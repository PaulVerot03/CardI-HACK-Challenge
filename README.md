# CardI-HACK Challenge Submission

This document outlines the approach taken for the CardI-HACK Challenge, how it adheres to the competition's constraints, and provides a guide to the files in this project.

## Compliance & Reproducibility (as per section 6.3)

### 6.3.1. Reproducible Package

This project is designed to be reproducible.

*   **Code:** All code for data exploration, model training, and evaluation is provided in the Python scripts.
*   **Environment:** The project uses a Python virtual environment to manage dependencies. To recreate the environment, create a virtual environment and install the following packages:
    ```bash
    pip install pandas scikit-learn
    ```
*   **README:** This file serves as the README to regenerate predictions from the raw challenge inputs.

### 6.3.2. Data Use Compliance

This project adheres strictly to the data use constraints. Only the provided `train.csv` and `test.csv` files were used for training and prediction. No external patient-level data was used.

### 6.3.3. Model Cards

*   **Models Used:** The final submission uses two `RandomForestClassifier` models from the `scikit-learn` library.
*   **Intended Use:** The models are intended to predict `OUTCOME_SEVERITY` and `OUTCOME_MACE` for patients with hypertrophic cardiomyopathy, based on the provided clinical and genetic data.
*   **Limitations:** The models are baseline implementations and have not been extensively hyperparameter-tuned. The Polygenic Risk Score (PRS) is a simple summation of SNP values and could be improved with more sophisticated methods.

## File Descriptions

*   `explore_data.py`: This script performs an initial exploration of the `train.csv` and `test.csv` datasets. It uses `pandas` to display information about the data, such as data types, missing values, and basic statistics.

*   `train_model.py`: This script trains a baseline model using only the clinical features and the `Variant.Pathogene` feature. It generates the `submission.csv` file.

*   `train_model_with_prs.py`: This script builds on the baseline model by adding a simple Polygenic Risk Score (PRS) as a feature. The PRS is calculated by summing the values of the first 75 SNPs. It generates the `submission_with_prs.csv` file.

*   `evaluate_models.py`: This script evaluates the performance of different feature sets using 5-fold cross-validation. It compares the performance of models with and without the genetic data (PRS and all SNPs) to determine the best features for each outcome. The metrics used for evaluation are Log Loss for `OUTCOME_SEVERITY` and Quadratic Weighted Kappa (QWK), Accuracy, and ROC AUC for `OUTCOME_MACE`.

*   `train_final_model.py`: This script trains the final models using the best feature sets identified in the evaluation step. It uses `Clinical + Variant + All SNPs` for `OUTCOME_SEVERITY` and `Clinical + Variant` for `OUTCOME_MACE`. It generates the `final_submission.csv` file.

*   `submission.csv`: A submission file generated by `train_model.py`.
*   `submission_with_prs.csv`: A submission file generated by `train_model_with_prs.py`.
*   `final_submission.csv`: The final submission file generated by `train_final_model.py`.
*   `.venv/`: This directory contains the Python virtual environment and its dependencies.

## How to Run

To regenerate the `final_submission.csv` file, follow these steps:

1.  **Set up the environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    pip install pandas scikit-learn
    ```

2.  **Run the final training script:**
    ```bash
    python3 train_final_model.py
    ```

This will create the `final_submission.csv` file in the current directory.
